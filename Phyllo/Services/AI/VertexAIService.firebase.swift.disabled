import Foundation
import UIKit
import FirebaseVertexAI
import FirebaseStorage

// MARK: - Vertex AI Service with Firebase
// Rename this file to VertexAIService.swift after Firebase is configured

// Use the same models from the mock service
// (MealAnalysisRequest, UserNutritionContext, MealAnalysisResult are defined in the mock file)

// MARK: - Vertex AI Service Implementation

@MainActor
class VertexAIService: ObservableObject {
    static let shared = VertexAIService()
    
    @Published var isAnalyzing = false
    @Published var analysisProgress: Double = 0.0
    
    private let model: GenerativeModel
    private let storage = Storage.storage()
    
    private init() {
        // Initialize Vertex AI through Firebase
        let vertexAI = VertexAI.vertexAI()
        
        // Use Gemini 2.5 Flash model
        self.model = vertexAI.generativeModel(
            modelName: "gemini-2.5-flash",
            generationConfig: GenerationConfig(
                temperature: 0.7,
                topK: 40,
                topP: 0.95,
                maxOutputTokens: 2048,
                responseMIMEType: "application/json"
            )
        )
    }
    
    // MARK: - Public Methods
    
    func analyzeMeal(_ request: MealAnalysisRequest) async throws -> MealAnalysisResult {
        isAnalyzing = true
        analysisProgress = 0.0
        
        defer {
            isAnalyzing = false
            analysisProgress = 1.0
        }
        
        // Compress image
        guard let imageData = compressImage(request.image) else {
            throw AnalysisError.imageCompressionFailed
        }
        
        analysisProgress = 0.2
        
        // Create prompt
        let prompt = createAnalysisPrompt(request)
        
        analysisProgress = 0.3
        
        // Call Vertex AI with Firebase AI Logic
        let result = try await callVertexAI(prompt: prompt, imageData: imageData)
        
        analysisProgress = 1.0
        
        return result
    }
    
    // MARK: - Private Methods
    
    private func compressImage(_ image: UIImage) -> Data? {
        // Resize to max 1024x1024 maintaining aspect ratio
        let maxDimension: CGFloat = 1024
        let scale = min(maxDimension / image.size.width, maxDimension / image.size.height)
        
        guard scale < 1 else {
            return image.jpegData(compressionQuality: 0.8)
        }
        
        let newSize = CGSize(
            width: image.size.width * scale,
            height: image.size.height * scale
        )
        
        UIGraphicsBeginImageContextWithOptions(newSize, false, 0)
        image.draw(in: CGRect(origin: .zero, size: newSize))
        let resizedImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        
        return resizedImage?.jpegData(compressionQuality: 0.8)
    }
    
    private func createAnalysisPrompt(_ request: MealAnalysisRequest) -> String {
        let windowInfo = request.mealWindow.map { window in
            """
            Current Window: \(window.purpose.displayName) (\(window.timeRemaining ?? 0) minutes remaining)
            Window Targets: \(window.targetCalories) cal, \(window.targetMacros.protein)g protein, \(window.targetMacros.carbs)g carbs, \(window.targetMacros.fat)g fat
            """
        } ?? "No active meal window"
        
        let voiceInfo = request.voiceTranscript.map { "VOICE DESCRIPTION: \($0)" } ?? ""
        
        return """
        You are an expert nutritionist analyzing a meal photo for precise tracking.
        
        USER CONTEXT:
        - Goal: \(request.userContext.primaryGoal.displayName)
        - Daily Targets: \(request.userContext.dailyMacros)
        - \(windowInfo)
        
        \(voiceInfo)
        
        ANALYZE THE MEAL IMAGE AND PROVIDE:
        
        1. MEAL IDENTIFICATION
           - Name: [concise meal name, max 4 words]
           - Confidence: [0.0-1.0]
           - Main Components: [list key ingredients]
        
        2. PORTION ESTIMATION
           - Use visual cues (plate size, utensils, hand comparison)
           - Estimate weight/volume for each component
           
        3. NUTRITION CALCULATION
           - Use USDA standard values
           - Account for cooking methods and added fats
           - Calories: [number]
           - Protein: [grams with 1 decimal]
           - Carbs: [grams with 1 decimal]
           - Fat: [grams with 1 decimal]
           
        4. MICRONUTRIENTS (top 5-8 most significant)
           - Focus on goal-relevant nutrients
           - Include vitamin/mineral name, amount, unit, and %RDA
           
        5. CLARIFICATION NEEDS
           - Only ask if confidence < 0.8 or critical info missing
           - Max 2 questions
           - Provide 3-4 multiple choice options per question
        
        FORMAT AS JSON:
        {
          "mealName": "string",
          "confidence": 0.0-1.0,
          "ingredients": [
            {"name": "string", "amount": "string", "unit": "string", "foodGroup": "string"}
          ],
          "nutrition": {
            "calories": number,
            "protein": number,
            "carbs": number,
            "fat": number
          },
          "micronutrients": [
            {"name": "string", "amount": number, "unit": "string", "percentRDA": number}
          ],
          "clarifications": [
            {"question": "string", "options": ["string"], "clarificationType": "portion|ingredient|preparation"}
          ]
        }
        """
    }
    
    private func callVertexAI(prompt: String, imageData: Data) async throws -> MealAnalysisResult {
        analysisProgress = 0.4
        
        // Upload image to Firebase Storage temporarily
        let imagePath = "temp_meal_images/\(UUID().uuidString).jpg"
        let imageRef = storage.reference().child(imagePath)
        
        let metadata = StorageMetadata()
        metadata.contentType = "image/jpeg"
        
        // Upload with automatic deletion after 24 hours
        metadata.customMetadata = ["deleteAfter": String(Date().addingTimeInterval(86400).timeIntervalSince1970)]
        
        _ = try await imageRef.putDataAsync(imageData, metadata: metadata)
        let imageURL = try await imageRef.downloadURL()
        
        analysisProgress = 0.5
        
        // Create multi-modal content with image and prompt
        let imageContent = ModelContent.Part.fileData(
            mimeType: "image/jpeg",
            url: imageURL.absoluteString
        )
        
        let textContent = ModelContent.Part.text(prompt)
        
        analysisProgress = 0.6
        
        // Generate content using Vertex AI
        let response = try await model.generateContent(imageContent, textContent)
        
        analysisProgress = 0.8
        
        // Parse the JSON response
        guard let text = response.text,
              let jsonData = text.data(using: .utf8) else {
            throw AnalysisError.invalidResponse
        }
        
        // Schedule image deletion
        Task {
            try? await Task.sleep(nanoseconds: 86_400_000_000_000) // 24 hours
            try? await imageRef.delete()
        }
        
        return try JSONDecoder().decode(MealAnalysisResult.self, from: jsonData)
    }
    
    // MARK: - Error Types
    
    enum AnalysisError: LocalizedError {
        case imageCompressionFailed
        case invalidResponse
        case networkError(String)
        case quotaExceeded
        
        var errorDescription: String? {
            switch self {
            case .imageCompressionFailed:
                return "Failed to process the image"
            case .invalidResponse:
                return "Invalid response from AI service"
            case .networkError(let message):
                return "Network error: \(message)"
            case .quotaExceeded:
                return "Daily analysis limit reached"
            }
        }
    }
}